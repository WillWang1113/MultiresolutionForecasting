{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wcx/multiresolution_forecasting/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "Please replace the variable ```pth``` into your new result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No adjusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Neural Laplace</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSTM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Persistence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.936882</td>\n",
       "      <td>0.380235</td>\n",
       "      <td>5.188830</td>\n",
       "      <td>0.09685</td>\n",
       "      <td>5.149303</td>\n",
       "      <td>0.091195</td>\n",
       "      <td>6.596242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.971793</td>\n",
       "      <td>0.267169</td>\n",
       "      <td>5.307560</td>\n",
       "      <td>0.19586</td>\n",
       "      <td>4.927910</td>\n",
       "      <td>0.118691</td>\n",
       "      <td>6.603842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.998867</td>\n",
       "      <td>0.349172</td>\n",
       "      <td>5.403205</td>\n",
       "      <td>0.15979</td>\n",
       "      <td>4.680242</td>\n",
       "      <td>0.086694</td>\n",
       "      <td>6.640212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neural Laplace                LSTM                MLP             \n",
       "             mean       std      mean      std      mean       std   \n",
       "1        4.936882  0.380235  5.188830  0.09685  5.149303  0.091195  \\\n",
       "3        4.971793  0.267169  5.307560  0.19586  4.927910  0.118691   \n",
       "12       4.998867  0.349172  5.403205  0.15979  4.680242  0.086694   \n",
       "\n",
       "   Persistence       \n",
       "          mean  std  \n",
       "1     6.596242  0.0  \n",
       "3     6.603842  0.0  \n",
       "12    6.640212  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# electricity load dataset (persistence: loop)\n",
    "# pth = \"results/mfred/example_benchmarks-20230831-041824\"\n",
    "\n",
    "# wind power dataset (persistence: naive)\n",
    "pth = \"results/nrel/example_benchmarks-20230817-231811\"\n",
    "# pth = \"results/mfred/example_benchmarks-20230814-210128\"\n",
    "\n",
    "# NL with one large Laplace decoder (failure)\n",
    "# pth = \"results/mfred/example_benchmarks-20231012-175829\"\n",
    "\n",
    "# model_names = ['Neural Laplace', 'LSTM', 'MLP']\n",
    "model_names = ['Neural Laplace', 'LSTM', 'MLP', 'Persistence']\n",
    "# model_names = ['Neural Laplace']\n",
    "fcst_features = [0]\n",
    "all_seed_result = []\n",
    "all_seed_preds = []\n",
    "for seed in range(20):\n",
    "    with open(f\"{pth}-{seed}.pkl\", \"rb\") as f:\n",
    "        all_result = pickle.load(f)\n",
    "    test_result = {name: {} for name in model_names}\n",
    "    test_preds_trajs = {name: {} for name in model_names}\n",
    "    for avg_terms in all_result:\n",
    "        result_avg = all_result[avg_terms]\n",
    "        train_mean = result_avg['train_mean'][fcst_features]\n",
    "        train_std = result_avg['train_std'][fcst_features]\n",
    "        num_avg_terms = int(avg_terms.split(\"_\")[-1])\n",
    "        for name in model_names:\n",
    "            model_results = result_avg[name]\n",
    "\n",
    "            test_preds = model_results[\"test_preds\"] * train_std.cpu().numpy(\n",
    "            ) + train_mean.cpu().numpy()\n",
    "            test_trajs = model_results[\"test_trajs\"] * train_std.cpu().numpy(\n",
    "            ) + train_mean.cpu().numpy()\n",
    "            pred_timesteps = test_trajs.shape[1]\n",
    "            # if num_avg_terms == 1:\n",
    "            #     fig, ax = plt.subplots()\n",
    "            #     ax.plot(test_trajs[300,:,0], label=\"real\")\n",
    "            #     ax.plot(test_preds[300,:,0], label=\"fcst\")\n",
    "            #     ax.legend()\n",
    "            #     ax.set(xlabel=\"Forecasting horizon\", ylabel=\"Load(kW)\")\n",
    "            #     # ax.set_title(name)\n",
    "            #     fig.savefig(\"savings/supp_NL.pdf\")\n",
    "            test_result[name][num_avg_terms] = mean_squared_error(\n",
    "                test_trajs.squeeze(), test_preds.squeeze(), squared=False)\n",
    "            test_preds_trajs[name][num_avg_terms] = deepcopy(\n",
    "                (test_preds, test_trajs))\n",
    "    df_test_result = pd.DataFrame(test_result)\n",
    "    all_seed_preds.append(test_preds_trajs)\n",
    "    all_seed_result.append(df_test_result)\n",
    "all_seed_result = pd.concat(all_seed_result, axis=0)\n",
    "all_seed_result = all_seed_result.groupby(all_seed_result.index).agg(\n",
    "    [\"mean\", \"std\"])\n",
    "all_seed_result = all_seed_result.sort_index()\n",
    "avg_terms_list = all_seed_result.index.tolist()\n",
    "all_seed_result\n",
    "# with open(f'savings/bench_20_{pth.split(\"/\")[1]}.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_seed_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean consistent error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5min vs 15min</th>\n",
       "      <th>5min vs 60min</th>\n",
       "      <th>15min vs 60min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Laplace</th>\n",
       "      <td>6.425709</td>\n",
       "      <td>7.581275</td>\n",
       "      <td>7.389087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>2.006866</td>\n",
       "      <td>5.986436</td>\n",
       "      <td>5.944163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>2.083820</td>\n",
       "      <td>3.931973</td>\n",
       "      <td>2.498962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                5min vs 15min  5min vs 60min  15min vs 60min\n",
       "Neural Laplace       6.425709       7.581275        7.389087\n",
       "LSTM                 2.006866       5.986436        5.944163\n",
       "MLP                  2.083820       3.931973        2.498962"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_avg_terms = max(avg_terms_list)\n",
    "mce_results = {name: [] for name in model_names}\n",
    "for seed in range(20):\n",
    "    preds_trajs_dict = all_seed_preds[seed]\n",
    "    for name in model_names:\n",
    "        mce = {\"5min vs 15min\":0, \"5min vs 60min\":0, \"15min vs 60min\":0}\n",
    "        for n, avg_terms in enumerate(avg_terms_list):\n",
    "\n",
    "            if avg_terms < max_avg_terms:\n",
    "                # print(\"current avg_terms\", avg_terms)\n",
    "                rest_avg_terms = avg_terms_list[n + 1:]\n",
    "                (test_preds, test_trajs) = preds_trajs_dict[name][avg_terms]\n",
    "                for r_avg_terms in rest_avg_terms:\n",
    "                    (real_avg_preds,\n",
    "                     real_avg_trajs) = preds_trajs_dict[name][r_avg_terms]\n",
    "                    # print(avg_terms, r_avg_terms)\n",
    "                    # calculate predictions\n",
    "                    avg_test_preds = np.split(test_preds,\n",
    "                                              test_preds.shape[1] //\n",
    "                                              (r_avg_terms // avg_terms),\n",
    "                                              axis=1)\n",
    "                    avg_test_preds = np.stack(\n",
    "                        [j.mean(axis=1) for j in avg_test_preds], axis=1)\n",
    "                    error = (avg_test_preds - real_avg_preds)**2\n",
    "                    mce[f\"{avg_terms*5}min vs {r_avg_terms*5}min\"] += error.mean()\n",
    "        # mce = pd.DataFrame(mce, index=0)\n",
    "        # print(mce)\n",
    "        mce_results[name].append(mce)\n",
    "\n",
    "all_model_mce = []\n",
    "for name in model_names:\n",
    "    \n",
    "    model_mce = pd.DataFrame(mce_results[name]).mean()\n",
    "    all_model_mce.append(model_mce)\n",
    "all_model_mce = pd.concat(all_model_mce, axis=1)\n",
    "all_model_mce = all_model_mce.T\n",
    "all_model_mce.index = model_names\n",
    "all_model_mce = all_model_mce.drop(\"Persistence\", axis=0)\n",
    "all_model_mce\n",
    "# mce_results.index = [0 for _ in range(20)]\n",
    "# mce_results = mce_results.groupby(mce_results.index).agg(\n",
    "    # [\"mean\", \"std\"])\n",
    "# mce_results.index= [\"MCE\"]\n",
    "# mce_results.mean()\n",
    "# mce_results.to_csv(f\"savings/bench_{pth.split('/')[1]}_mce.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. After adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bottom up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Neural Laplace-BU</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSTM-BU</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLP-BU</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Persistence-BU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.994273</td>\n",
       "      <td>0.405666</td>\n",
       "      <td>5.317320</td>\n",
       "      <td>0.103603</td>\n",
       "      <td>5.214271</td>\n",
       "      <td>0.093587</td>\n",
       "      <td>6.884816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.987119</td>\n",
       "      <td>0.406156</td>\n",
       "      <td>5.306487</td>\n",
       "      <td>0.104206</td>\n",
       "      <td>5.191459</td>\n",
       "      <td>0.092432</td>\n",
       "      <td>6.879671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.927970</td>\n",
       "      <td>0.410021</td>\n",
       "      <td>5.250381</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>5.129826</td>\n",
       "      <td>0.092773</td>\n",
       "      <td>6.837363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neural Laplace-BU             LSTM-BU              MLP-BU             \n",
       "                mean       std      mean       std      mean       std   \n",
       "1           4.994273  0.405666  5.317320  0.103603  5.214271  0.093587  \\\n",
       "3           4.987119  0.406156  5.306487  0.104206  5.191459  0.092432   \n",
       "12          4.927970  0.410021  5.250381  0.105409  5.129826  0.092773   \n",
       "\n",
       "   Persistence-BU       \n",
       "             mean  std  \n",
       "1        6.884816  0.0  \n",
       "3        6.879671  0.0  \n",
       "12       6.837363  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bu_results, all_bu_preds = [], []\n",
    "for seed in range(20):\n",
    "    preds_trajs_dict = all_seed_preds[seed]\n",
    "    bu_results = {name + \"-BU\": {} for name in model_names}\n",
    "    bu_preds = {name + \"-BU\": {} for name in model_names}\n",
    "    for name in model_names:\n",
    "        for avg_terms in avg_terms_list:\n",
    "            (test_preds, test_trajs) = preds_trajs_dict[name][1]\n",
    "            # Test trajs are consistent\n",
    "            avg_test_trajs = np.split(test_trajs,\n",
    "                                      test_trajs.shape[1] // avg_terms,\n",
    "                                      axis=1)\n",
    "            avg_test_trajs = np.stack([j.mean(axis=1) for j in avg_test_trajs],\n",
    "                                      axis=1)\n",
    "\n",
    "            # calculate predictions\n",
    "            avg_test_preds = np.split(test_preds,\n",
    "                                      test_preds.shape[1] // avg_terms,\n",
    "                                      axis=1)\n",
    "            avg_test_preds = np.stack([j.mean(axis=1) for j in avg_test_preds],\n",
    "                                      axis=1)\n",
    "            bu_results[name + \"-BU\"][avg_terms] = mean_squared_error(\n",
    "                avg_test_trajs.flatten(),\n",
    "                avg_test_preds.flatten(),\n",
    "                squared=False)\n",
    "            bu_preds[name + \"-BU\"][avg_terms] = (avg_test_preds,avg_test_trajs\n",
    "                                                 )\n",
    "\n",
    "            # if avg_terms == 3:\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(avg_test_trajs[0,:,0])\n",
    "            # ax.plot(avg_test_preds[0,:,0])\n",
    "\n",
    "    bu_results = pd.DataFrame(bu_results)\n",
    "    all_bu_results.append(bu_results)\n",
    "    all_bu_preds.append(bu_preds)\n",
    "all_bu_results = pd.concat(all_bu_results, axis=0)\n",
    "all_bu_results = all_bu_results.groupby(all_bu_results.index).agg(\n",
    "    [\"mean\", \"std\"])\n",
    "all_bu_results = all_bu_results.sort_index()\n",
    "all_bu_results\n",
    "# with open(f'savings/bench_bu_20_{pth.split(\"/\")[1]}.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_bu_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# all_bu_results.to_csv(\"savings/benchmark_bu.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athanasopoulos, George, et al. \"Forecasting with temporal hierarchies.\" European Journal of Operational Research 262.1 (2017): 60-74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Neural Laplace-OPT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSTM-OPT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLP-OPT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Persistence-OPT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.860383</td>\n",
       "      <td>0.331628</td>\n",
       "      <td>5.299112</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>5.089091</td>\n",
       "      <td>0.076269</td>\n",
       "      <td>6.883998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.853041</td>\n",
       "      <td>0.332068</td>\n",
       "      <td>5.288247</td>\n",
       "      <td>0.091614</td>\n",
       "      <td>5.065711</td>\n",
       "      <td>0.075272</td>\n",
       "      <td>6.878853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.792563</td>\n",
       "      <td>0.335591</td>\n",
       "      <td>5.231973</td>\n",
       "      <td>0.092663</td>\n",
       "      <td>5.003829</td>\n",
       "      <td>0.075829</td>\n",
       "      <td>6.836540</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neural Laplace-OPT            LSTM-OPT             MLP-OPT             \n",
       "                 mean       std      mean       std      mean       std   \n",
       "1            4.860383  0.331628  5.299112  0.091206  5.089091  0.076269  \\\n",
       "3            4.853041  0.332068  5.288247  0.091614  5.065711  0.075272   \n",
       "12           4.792563  0.335591  5.231973  0.092663  5.003829  0.075829   \n",
       "\n",
       "   Persistence-OPT       \n",
       "              mean  std  \n",
       "1         6.883998  0.0  \n",
       "3         6.878853  0.0  \n",
       "12        6.836540  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "S = [\n",
    "    block_diag(*[[1.0 / s for _ in range(s)]\n",
    "                 for _ in range(pred_timesteps // s)]) for s in avg_terms_list\n",
    "]\n",
    "S.reverse()\n",
    "S = np.concatenate(S)\n",
    "S = S @ np.linalg.inv(S.T @ S) @ S.T\n",
    "\n",
    "all_opt_results, all_opt_preds = [], []\n",
    "for seed in range(20):\n",
    "    preds_trajs_dict = all_seed_preds[seed]\n",
    "    opt_results = {name + \"-OPT\": {} for name in model_names}\n",
    "    opt_preds = {name + \"-OPT\": {} for name in model_names}\n",
    "    for name in model_names:\n",
    "        preds_vec, trajs_vec, pred_steps = [], [], []\n",
    "        for avg_terms in avg_terms_list[::-1]:\n",
    "            (test_preds, test_trajs) = preds_trajs_dict[name][avg_terms]\n",
    "            preds_vec.append(test_preds.copy())\n",
    "            trajs_vec.append(test_trajs.copy())\n",
    "        preds_vec = np.concatenate(preds_vec, axis=1)\n",
    "        # preds_vec = preds_vec.transpose(1, 0, 2)\n",
    "        adjusted_preds = np.tensordot(S, preds_vec, axes=[1, 1])\n",
    "        start = 0\n",
    "        for i, trajs in enumerate(trajs_vec):\n",
    "            steps = trajs.shape[1]\n",
    "            opt_results[name +\n",
    "                        \"-OPT\"][avg_terms_list[::-1][i]] = mean_squared_error(\n",
    "                            trajs.flatten(),\n",
    "                            adjusted_preds[start:start + steps,\n",
    "                                           ...].transpose(1, 0, 2).flatten(),\n",
    "                            squared=False)\n",
    "            opt_preds[name + \"-OPT\"][avg_terms_list[::-1][i]] = (\n",
    "                adjusted_preds[start:start + steps, ...].transpose(1, 0,\n",
    "                                                                   2), trajs)\n",
    "            # if i == 0:\n",
    "            #     fig, ax = plt.subplots()\n",
    "            #     ax.plot(trajs[0].flatten())\n",
    "            #     ax.plot(adjusted_preds[start:start + steps, 0, :].flatten())\n",
    "            #     print(adjusted_preds[start:start + steps, 0, :].flatten())\n",
    "            start += steps\n",
    "\n",
    "    opt_results = pd.DataFrame(opt_results)\n",
    "    all_opt_results.append(opt_results)\n",
    "    all_opt_preds.append(opt_preds)\n",
    "\n",
    "all_opt_results = pd.concat(all_opt_results, axis=0)\n",
    "all_opt_results = all_opt_results.groupby(all_opt_results.index).agg(\n",
    "    [\"mean\", \"std\"])\n",
    "all_opt_results = all_opt_results.sort_index()\n",
    "# all_opt_results.to_csv(\"savings/benchmark_opt.csv\")\n",
    "# with open(f'savings/bench_opt_20_{pth.split(\"/\")[1]}.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_opt_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "all_opt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical NL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace the variable ```pth``` into your new result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hierarchical NL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.641777</td>\n",
       "      <td>0.252007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.616905</td>\n",
       "      <td>0.248384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.538334</td>\n",
       "      <td>0.250710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hierarchical NL          \n",
       "              mean       std\n",
       "1         4.641777  0.252007\n",
       "3         4.616905  0.248384\n",
       "12        4.538334  0.250710"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load\n",
    "# pth = \"results/mfred/example-20230815-052223\"\n",
    "\n",
    "# Wind\n",
    "pth = \"results/nrel/example-20230819-070441\"\n",
    "\n",
    "\n",
    "all_seed_result = []\n",
    "all_seed_preds = []\n",
    "fcst_features = [0]\n",
    "for seed in range(20):\n",
    "    with open(f\"{pth}-{seed}.pkl\", \"rb\") as f:\n",
    "        result = pickle.load(f)\n",
    "        avg_terms_list = result[\"model_hyperparams\"][\"avg_terms_list\"]\n",
    "        # print(result[\"model_hyperparams\"][\"encoder\"])\n",
    "        train_mean = result[\"train_mean\"][fcst_features].detach().cpu().numpy()\n",
    "        train_std = result[\"train_std\"][fcst_features].detach().cpu().numpy()\n",
    "\n",
    "        model = result[\"Hierarchical NL\"]\n",
    "        # avg_terms_list = result[\"avg_terms_list\"]\n",
    "        # print(result[\"train_mean\"])\n",
    "        # print(result[\"train_std\"])\n",
    "        test_label = model[\"test_trajs\"]\n",
    "        test_preds = model[\"test_preds\"]\n",
    "        test_label = test_label\n",
    "        test_label = test_label * train_std + train_mean\n",
    "        pred_timesteps = test_label.shape[1]\n",
    "\n",
    "    avg_test_label, avg_test_preds, rmse = {}, {}, {}\n",
    "    for i, avg_terms in enumerate(avg_terms_list):\n",
    "        temp = np.split(test_label, test_label.shape[1] // avg_terms, axis=1)\n",
    "        temp = np.stack([j.mean(axis=1) for j in temp], axis=1)\n",
    "        avg_test_label[avg_terms] = temp\n",
    "        # avg_test_preds[avg_terms] = (test_preds[i].detach().cpu().numpy(\n",
    "        # ), temp)\n",
    "        avg_test_preds[avg_terms] = (\n",
    "            test_preds[i].detach().cpu().numpy() * train_std + train_mean,\n",
    "            temp)\n",
    "\n",
    "        # print(avg_test_preds[avg_terms][0].flatten())\n",
    "        rmse[avg_terms] = [\n",
    "            mean_squared_error(temp.squeeze(),\n",
    "                               avg_test_preds[avg_terms][0].squeeze(),\n",
    "                               squared=False)\n",
    "        ]\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.plot(temp[3,:,0])\n",
    "        # ax.plot(avg_test_preds[avg_terms][0][3,:,0])\n",
    "    rmse = pd.DataFrame(rmse).transpose()\n",
    "    all_seed_result.append(rmse)\n",
    "    all_seed_preds.append(avg_test_preds)\n",
    "all_seed_result = pd.concat(all_seed_result, axis=0)\n",
    "all_seed_result = all_seed_result.groupby(all_seed_result.index).agg(\n",
    "    [\"mean\", \"std\"])\n",
    "avg_terms_list = all_seed_result.index.tolist()\n",
    "all_seed_result = all_seed_result.rename(columns={0: \"Hierarchical NL\"})\n",
    "all_seed_result\n",
    "\n",
    "# with open(f'savings/proposed_20_{pth.split(\"/\")[1]}.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_seed_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean consistence error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed  5min vs 15min  5min vs 60min  15min vs 60min\n",
      "0          0.026094       0.222991        0.135184\n",
      "1          0.006738       0.086766        0.063191\n",
      "2          0.072298       0.472124        0.297841\n",
      "3          0.008204       0.151570        0.117880\n",
      "4          0.050868       0.284752        0.160015\n",
      "5          0.037831       0.270309        0.151035\n",
      "6          0.041395       0.323505        0.176930\n",
      "7          0.006382       0.125603        0.090764\n",
      "8          0.010175       0.172496        0.126226\n",
      "9          0.065932       0.472889        0.260358\n",
      "10         0.022158       0.215032        0.128669\n",
      "11         0.075076       0.805726        0.516497\n",
      "12         0.027309       0.180347        0.103134\n",
      "13         0.067109       0.433050        0.230927\n",
      "14         0.060076       0.613812        0.363339\n",
      "15         0.038062       0.286358        0.149500\n",
      "16         0.017503       0.201247        0.126916\n",
      "17         0.008451       0.131688        0.089743\n",
      "18         0.014225       0.178021        0.122130\n",
      "19         0.062784       0.256006        0.132002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neural Laplace</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>MLP</th>\n",
       "      <th>HL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5min vs 15min</th>\n",
       "      <td>6.425709</td>\n",
       "      <td>2.006866</td>\n",
       "      <td>2.083820</td>\n",
       "      <td>0.035933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5min vs 60min</th>\n",
       "      <td>7.581275</td>\n",
       "      <td>5.986436</td>\n",
       "      <td>3.931973</td>\n",
       "      <td>0.294215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15min vs 60min</th>\n",
       "      <td>7.389087</td>\n",
       "      <td>5.944163</td>\n",
       "      <td>2.498962</td>\n",
       "      <td>0.177114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Neural Laplace      LSTM       MLP        HL\n",
       "5min vs 15min         6.425709  2.006866  2.083820  0.035933\n",
       "5min vs 60min         7.581275  5.986436  3.931973  0.294215\n",
       "15min vs 60min        7.389087  5.944163  2.498962  0.177114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_avg_terms = max(avg_terms_list)\n",
    "mce_results = {}\n",
    "for seed in range(20):\n",
    "    preds_trajs_dict = all_seed_preds[seed]\n",
    "    mce = {\"5min vs 15min\":0, \"5min vs 60min\":0, \"15min vs 60min\":0}\n",
    "    for n, avg_terms in enumerate(avg_terms_list):\n",
    "\n",
    "        if avg_terms < max_avg_terms:\n",
    "            # print(\"current avg_terms\", avg_terms)\n",
    "            rest_avg_terms = avg_terms_list[n + 1:]\n",
    "            test_preds, _ = preds_trajs_dict[avg_terms]\n",
    "            for r_avg_terms in rest_avg_terms:\n",
    "                real_avg_preds, _ = preds_trajs_dict[r_avg_terms]\n",
    "\n",
    "                # print(avg_terms, r_avg_terms)\n",
    "                # calculate predictions\n",
    "                avg_test_preds = np.split(test_preds,\n",
    "                                          test_preds.shape[1] //\n",
    "                                          (r_avg_terms // avg_terms),\n",
    "                                          axis=1)\n",
    "                avg_test_preds = np.stack(\n",
    "                    [j.mean(axis=1) for j in avg_test_preds], axis=1)\n",
    "                error = (avg_test_preds - real_avg_preds)**2\n",
    "                mce[f\"{avg_terms*5}min vs {r_avg_terms*5}min\"] += error.mean()\n",
    "    mce_results[seed] = mce\n",
    "    # mce_results[seed] = [mce]\n",
    "mce_results = pd.DataFrame(mce_results)\n",
    "mce_results.index.name = \"seed\"\n",
    "mce_results = mce_results.transpose()\n",
    "print(mce_results)\n",
    "# mce_results.columns=[\"Hierarchical NL\"]\n",
    "# mce_results.index = [0 for _ in range(20)]\n",
    "mce_results = mce_results.mean()\n",
    "# mce_results.index= [\"MCE\"]\n",
    "all_model_mce = pd.concat([all_model_mce.T, mce_results], axis=1)\n",
    "all_model_mce.rename(columns={0:\"HL\"}, inplace=True)\n",
    "all_model_mce\n",
    "# hnl = pd.concat([all_seed_result, mce_results])\n",
    "# benchmarks = pd.read_csv(\"savings/benchmark_raw.csv\", index_col=0, header=[0,1])\n",
    "# benchmarks.index = hnl.index\n",
    "# all_results = pd.concat([benchmarks, hnl], axis=1)\n",
    "# print(all_results)\n",
    "# mce_results.to_csv(f\"savings/proposed_{pth.split('/')[1]}_mce.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGjCAYAAAA2Hv8iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFRUlEQVR4nO3de1yUdf7//+d4GiBkQEUBxagoz8cFTDdTOyjmsUTRdBW1rEwr01x1K8AMLNE+ba6WleGmrppRqWmaFW3mkSyrr5qWWgp4lpMKcpjfH/6YbeSMDHjB4367ze3mvK/3+7peMwPOk+t6X9dlslqtVgEAABhQraouAAAAoLwIMgAAwLAIMgAAwLAIMgAAwLAIMgAAwLAIMgAAwLAIMgAAwLAIMgAAwLDqVHUBjpaXl6ekpCTVr19fJpOpqssBAAClYLValZ6eLh8fH9WqVfR+l2ofZJKSkuTr61vVZQAAgHI4fvy4mjVrVuTyah9k6tevL+nqG+Hm5lbF1QAAgNJIS0uTr6+v7Xu8KNU+yOQfTnJzcyPIAABgMCVNC2GyLwAAMCyCDAAAMCyCDAAAMCyCDAAAMKxqP9m3LHJzc5WdnV3VZQCVqm7duqpdu3ZVlwEA5UKQ0dWL7pw8eVIpKSlVXQpQJdzd3eXl5cVFIwEYDkFGsoWYxo0by8XFhf/MUWNYrVZdunRJp0+fliR5e3tXcUUAUDY1Psjk5ubaQkzDhg2ruhyg0jk7O0uSTp8+rcaNG3OYCYCh1PjJvvlzYlxcXKq4EqDq5P/8M0cMgNHU+CCTj8NJqMn4+QdgVAQZAABgWAQZAABgWAQZVIiwsDD5+flVdRmGZzKZFBERUdVlAIBhEGSqsfj4eJlMpkIfO3furOryqlRGRobCw8MVHBysBg0ayGQyKTY2ttC+YWFhhb6HLVu2rNyiAQAF1PjTr0uSlHK5qkuQj7vzdY1/6qmnFBgYaNfm7+9/Xeu81ttvv628vLwKXacjnT17VrNnz1bz5s3VoUMHxcfHF9vfbDbrnXfesWuzWCwVXtfly5dVpw6/lkBVm79oR1WXYBhTJ3at0u3zP2YN0L17d4WEhDh0G3Xr1nXo+iuat7e3kpOT5eXlpYSEhAJB71p16tTRqFGjHF6Xk5OTw7cBANUJh5ZqiPT0dOXk5BS53GQyadKkSfrggw/UunVrOTs7q2vXrvrpp58kSW+99Zb8/f3l5OSknj176tixY3bjr50jc+zYMZlMJsXExGjJkiW67bbbZDabFRgYqD179hRba0JCgkwmk5YtW1Zg2ebNm2UymbRhwwbb63rmmWfk5+cns9msxo0b6/7779fevXuL3YbZbJaXl1exfa6Vm5urtLS0IpfHxsbKZDJp27Zteuqpp+Tp6Sl3d3c99thjunLlilJSUjR69Gh5eHjIw8ND06dPl9VqtVvHtXNkIiIiZDKZ9OuvvyosLEzu7u6yWCwaO3asLl26VKb6AaA6IsjUAGPHjpWbm5ucnJzUq1cvJSQkFNrvm2++0dSpUzVmzBhFRETowIED6t+/v/71r3/pn//8pyZOnKjnnntOO3bs0Lhx40q17ZUrV2revHl67LHHNGfOHB07dkwPPfRQsRdeCwgI0K233qo1a9YUWLZ69Wp5eHioT58+kqTHH39cixcv1pAhQ7Ro0SJNmzZNzs7OOnDgQKnqK61Lly7Jzc1NFotFDRo00JNPPqmMjIxC+06ePFmHDx9WZGSkBg4cqCVLluiFF17QgAEDlJubq6ioKN11112aN2+e3n///VJtf9iwYUpPT1d0dLSGDRum2NhYRUZGVuRLBABD4tBSNVavXj0NGTJEDzzwgBo1aqT9+/crJiZG3bt31/bt29WpUye7/r/88osOHjxo27Pi4eFhCyCHDh1S/fr1JV3dMxEdHa1jx46VeKbSH3/8ocOHD8vDw0OS1KJFCw0aNEibN29W//79ixwXGhqqmJgYXbhwwTb2ypUr+uijj/TQQw/ZDmV9+umnevTRRzV//nzb2OnTp5fpfSqJt7e3pk+frs6dOysvL0+fffaZFi1apH379ik+Pr7AnJYmTZpo48aNMplMmjhxon799VdbmFu8eLEkacKECfLz89PSpUs1evToEmvo1KmT3n33Xdvzc+fO6d1339Urr7xSoa8VAIyGPTLVWLdu3bR27VqNGzdOAwcO1IwZM7Rz506ZTCbNnDmzQP97773XLph06dJFkjRkyBBbiPlz+5EjR0qsITQ01BZEpKvzdUozNjQ0VNnZ2YqLi7O1bdmyRSkpKQoNDbW1ubu7a9euXUpKSiqxlvKKjo7W3LlzNWzYMA0fPlyxsbF6+eWX9e2332rt2rUF+o8fP97uSrldunSR1WrV+PHjbW21a9dWQEBAqd5D6eqepz/r3r27zp07V+yhLgCoCQgyNYy/v78GDRqkr776Srm5uXbLmjdvbvc8/6wcX1/fQtsvXLhQ4vauXWd+qClpbIcOHdSyZUutXr3a1rZ69Wo1atRI99xzj63t1Vdf1c8//yxfX18FBQUpIiKi1OHgekyZMkW1atXS1q1bCywry/tYmvewsHWW9n0EgOqOIFMD+fr66sqVK7p48aJde1F3PS6q/dqJqhU9NjQ0VF999ZXOnj2rrKwsrVu3TkOGDLE7lDNs2DAdOXJEb7zxhnx8fDRv3jy1adNGmzZtKnH918PZ2VkNGzbU+fPnCywry/tYmvehuHWWdjwAVFcEmRroyJEjcnJykqura1WXUqzQ0FDl5OToww8/1KZNm5SWlqbhw4cX6Oft7a2JEyfq448/1tGjR9WwYUO9/PLLDq0tPT1dZ8+elaenp0O3AwAoHpN9q7EzZ84U+KLdt2+f1q1bp759+6pWrRs7x7Zq1Urt2rXT6tWr1aRJE3l7e+vuu++2Lc/NzVVGRobdhekaN24sHx8fZWVlVUgNmZmZys7OtpsjJEkvvfSSrFargoODK2Q7AIDyIchUY6GhoXJ2dla3bt3UuHFj7d+/X0uWLJGLi4vmzp1b1eWVSmhoqF588UU5OTlp/PjxduErPT1dzZo1U0hIiDp06CBXV1dt3bpVe/bssTuLqSgLFy5USkqKbaLw+vXrdeLECUlXT6G2WCw6efKkOnXqpBEjRthuSbB582Zt3LhRwcHBGjRokANeNQCgtAgy1djgwYO1YsUKLViwQGlpafL09NRDDz2k8PDwCr9FgaOEhobq+eef16VLl+zOVpIkFxcXTZw4UVu2bFFcXJzy8vLk7++vRYsW6Yknnihx3TExMfr9999tz+Pi4mxnSY0aNUoWi0Xu7u7q37+/Pv/8cy1btky5ubny9/dXVFSUpk2bdsPv1QKA6s5kreazBdPS0mSxWJSamio3N7cCyzMzM3X06FHdcsstXB4eNRa/B4A97rVUeo6611JJ39/5+HMSAAAYFkEGAAAYFkEGAAAYFkEGAAAYFkEGAAAYVpmCzJ49ezRp0iS1adNGN910k5o3b65hw4bp0KFDBfoeOHBAwcHBcnV1VYMGDfS3v/1NZ86cKfW21q1bp86dO8vJyUnNmzdXeHi4cnJyylIuAACo5sp0HZlXXnlF3377rYYOHar27dvr5MmTWrhwoTp37qydO3eqbdu2kqQTJ07o7rvvlsViUVRUlDIyMhQTE6OffvpJu3fvVr169YrdzqZNmzR48GD17NlTb7zxhn766SfNmTNHp0+f1uLFi8v/agEAQLVSpiDz7LPPauXKlXZBJDQ0VO3atdPcuXO1fPlySVJUVJQuXryo7777znbX3qCgIN1///2KjY3VhAkTit3OtGnT1L59e23ZssV2g0A3NzdFRUXp6aeftl1hFQAA1GxlOrTUrVu3AntTbr/9drVp00YHDhywtX344Yfq37+/LcRI0n333ac77rhDa9asKXYb+/fv1/79+zVhwgS7uxxPnDhRVqtVa9euLUvJAACgGrvuyb5Wq1WnTp1So0aNJEmJiYk6ffq0AgICCvQNCgrS999/X+z68pdfO97Hx0fNmjUrcXxWVpbS0tLsHgAAoHq67iCzYsUKJSYm2u6Dk5ycLEny9vYu0Nfb21vnz58v9s7EJY3Pv8FfUaKjo2WxWGwPX1/fUr8WAABgLNcVZA4ePKgnn3xSXbt21ZgxYyRJly9fliSZzeYC/fPv4ZLfpzAljS9urCTNnDlTqamptsfx48dL92JwXcLCwuTn51fVZRjasWPHZDKZFBsbW9WlAIBhlDvInDx5Uv369ZPFYtHatWtVu3ZtSZKzs7MkFbrXJTMz065PYUoaX9xY6WoAcnNzs3vUVPHx8TKZTIU+du7cWdXl3RD27t2rgQMHqkGDBnJxcVHbtm31z3/+s0C/7du366677pKLi4u8vLz01FNPKSMjowoqBgD8WZnOWsqXmpqqvn37KiUlRd988418fHxsy/IPCeUfIvqz5ORkNWjQoNC9LYWNv/awUHJysoKCgspTcrmt3/NHpW6vMAMCm5fcqRhPPfWUAgMD7dr8/f2va53Xevvtt5WXl1eh63S0LVu2aMCAAerUqZNeeOEFubq66rffftOJEyfs+v3www+699571apVKy1YsEAnTpxQTEyMDh8+rE2bNlVYPTfffLMuX76sunXrVtg6AaC6K3OQyczM1IABA3To0CFt3bpVrVu3tlvetGlTeXp6KiEhocDY3bt3q2PHjsWuP395QkKCXWhJSkrSiRMnSjx1GwV1795dISEhDt2G0b5809LSNHr0aPXr109r165VrVpF75ycNWuWPDw8FB8fb9vD5+fnp0cffVRbtmxR7969K6Qmk8lkO/wKACidMh1ays3NVWhoqHbs2KEPPvhAXbt2LbTfkCFDtGHDBrv5KV988YUOHTqkoUOH2tqys7N18OBBu703bdq0UcuWLbVkyRLl5uba2hcvXiyTyeTwL+TqKj09vdgrI5tMJk2aNEkffPCBWrduLWdnZ3Xt2lU//fSTJOmtt96Sv7+/nJyc1LNnTx07dsxu/LVzZPLne8TExGjJkiW67bbbZDabFRgYqD179hRba0JCgkwmk5YtW1Zg2ebNm2UymbRhwwbb63rmmWfk5+cns9msxo0b6/7779fevXuL3cbKlSt16tQpvfzyy6pVq5YuXrxY6B6ltLQ0ff755xo1apTdYcrRo0fL1dXV7nICERERMplMOnTokEaNGiWLxSJPT0+98MILslqtOn78uAYNGiQ3Nzd5eXlp/vz5dtsqbI5MWFiYXF1dlZiYqMGDB8vV1VWenp6aNm2a3e8HANRUZQoyU6dO1bp169S3b1+dP39ey5cvt3vkmzVrllxcXNSrVy+98cYbio6O1tChQ9WuXTuNHTvW1i8xMVGtWrXSzJkz7bYzb948/fjjj+rdu7fefvttPf3004qKitIjjzyiVq1aXedLrnnGjh0rNzc3OTk5qVevXoXuLZOkb775RlOnTtWYMWMUERGhAwcOqH///vrXv/6lf/7zn5o4caKee+457dixQ+PGjSvVtleuXKl58+bpscce05w5c3Ts2DE99NBDys7OLnJMQECAbr311kKvObR69Wp5eHioT58+kqTHH39cixcv1pAhQ7Ro0SJNmzZNzs7Odtc1KszWrVvl5uamxMREtWjRQq6urnJzc9MTTzxhm8slST/99JNycnIKXA6gXr166tixY6GXAwgNDVVeXp7mzp2rLl26aM6cOfq///s/3X///WratKleeeUV+fv7a9q0afrvf/9bbJ3S1T8g+vTpo4YNGyomJkY9evTQ/PnztWTJkhLHAkB1V6ZDSz/88IMkaf369Vq/fn2B5aNGjZIk+fr66uuvv9azzz6rGTNmqF69eurXr5/mz59f7PyYfP3791dcXJwiIyM1efJkeXp6atasWXrxxRfLUm6NV69ePQ0ZMkQPPPCAGjVqpP379ysmJkbdu3fX9u3b1alTJ7v+v/zyiw4ePGjbs+Lh4WELIIcOHVL9+vUlXf1ijY6O1rFjx0o8U+mPP/7Q4cOH5eHhIUlq0aKFBg0apM2bN6t///5FjgsNDVVMTIwuXLhgG3vlyhV99NFHeuihh2yHsj799FM9+uijdns3pk+fXuJ7c/jwYeXk5GjQoEEaP368oqOjFR8frzfeeEMpKSn6z3/+I6nkywF88803BdqDgoL01ltvSZImTJggPz8/TZ06VdHR0fr73/8uSRoxYoR8fHy0dOlS3X333cXWmpmZqdDQUL3wwguSroa3zp07691339UTTzxR4msFgOqsTEEmPj6+1H3btGmjzZs3F9vHz89PVqu10GWDBw/W4MGDy1AdrtWtWzd169bN9nzgwIEKCQlR+/btNXPmTH322Wd2/e+99167YNKlSxdJVw8V5oeYP7cfOXKkxCATGhpqCyLS1fk6+WNLGhcdHa24uDiNHz9e0tXJuSkpKbZrFkmSu7u7du3apaSkJLtJ5yXJyMjQpUuX9Pjjj9vOUnrooYd05coVvfXWW5o9e7Zuv/32cl0O4JFHHrH9u3bt2goICNCJEydsryO/7hYtWpT4PuR7/PHH7Z53795d77//fqnGAkB1dt0XxIOx+Pv7a9CgQfrqq68KzLH48y0lJMlisUhSgbPH8tsvXLhQ4vauXWd+qClpbIcOHdSyZUutXr3a1rZ69Wo1atRI99xzj63t1Vdf1c8//yxfX18FBQUpIiKiVOEg/zT+ESNG2LU//PDDkqQdO3bY9SvL5QAKex+dnJxsV7/+c3tp3kMnJyd5enratXl4eJRqLABUdwSZGsjX11dXrlzRxYsX7drzrwV0raLai9qbVlFjQ0ND9dVXX+ns2bPKysrSunXrNGTIELt7cA0bNkxHjhzRG2+8IR8fH82bN09t2rQp8bTo/L03TZo0sWtv3LixpP8FrZIuJ1DYXqDCXrMj3kMAAEGmRjpy5IicnJzk6upa1aUUKzQ0VDk5Ofrwww+1adMmpaWlafjw4QX6eXt7a+LEifr444919OhRNWzYUC+//HKx6/7LX/4i6eqE8z/LvwVG/h6Qtm3bqk6dOgUmSF+5ckU//PBDiZcTAAA4FkGmGjtz5kyBtn379mndunXq3bt3sddOuRG0atVK7dq10+rVq7V69Wp5e3vbTYzNzc1Vamqq3ZjGjRvLx8en2Pt5SVf35EjSu+++a9f+zjvvqE6dOurZs6ekq4d/7rvvPi1fvlzp6em2fu+//74yMjLsLicAAKh85bqyL4whNDRUzs7O6tatmxo3bqz9+/dryZIlcnFx0dy5c6u6vFIJDQ3Viy++KCcnJ40fP94ufKWnp6tZs2YKCQlRhw4d5Orqqq1bt2rPnj0FrtFyrU6dOmncuHFaunSpcnJy1KNHD8XHx+uDDz7QzJkz7Q4Zvfzyy+rWrZt69OihCRMm6MSJE5o/f7569+6t4OBgh712AEDJCDLV2ODBg7VixQotWLBAaWlp8vT01EMPPaTw8PAKv0WBo4SGhur555/XpUuX7M5WkiQXFxdNnDhRW7ZsUVxcnPLy8uTv769FixaV6rTkN998U82bN9d7772njz76SDfffLNee+01PfPMM3b9OnfurK1bt+rvf/+7pkyZovr169tO2QYAVC2TtTSzDQ0sLS1NFotFqamphd5AMjMzU0ePHtUtt9zC5eFRY/F7ANibv2hHVZdgGFMnFn6V/+tV0vd3vht7kgQAAEAxCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDKodCaTSREREVVdhqFFRETIZDJVdRkAUOUIMtVYRkaGwsPDFRwcrAYNGshkMik2NrbQvmFhYTKZTAUeLVu2rNyib1B5eXlavHixOnbsKGdnZzVs2FD33HOP9u3bV6Dfq6++aruLdPv27fWf//yniqoGgOqvTlUXcKO7EW7lXt5bpJ89e1azZ89W8+bN1aFDB8XHxxfb32w265133rFrs1gs5dp2cS5fvqw6dYz1ozdu3DitWLFCo0eP1qRJk3Tx4kV9//33On36tF2/f/zjH5o7d64effRRBQYG6pNPPtHDDz8sk8mk4cOHV1g9zz//vGbMmFFh6wMAozLWtwnKxNvbW8nJyfLy8lJCQoICAwOL7V+nTh2NGjXK4XU5OTk5fBsVac2aNVq2bJni4uL04IMPFtkvMTFR8+fP15NPPqmFCxdKkh555BH16NFDzz33nIYOHaratWtXSE116tQxXBgEAEfg0FI1Zjab5eXlVaYxubm5SktLK3J5bGysTCaTtm3bpqeeekqenp5yd3fXY489pitXriglJUWjR4+Wh4eHPDw8NH36dFmtVrt1XDtHJn++x6+//qqwsDC5u7vLYrFo7NixunTpUrH1Tpo0Sa6uroX2GzFihLy8vJSbmytJSkhIUJ8+fdSoUSM5Ozvrlltu0bhx40p8TxYsWKCgoCA9+OCDysvL08WLFwvt98knnyg7O1sTJ060e61PPPGETpw4oR07/rd3z8/PT/3791d8fLwCAgLk7Oysdu3a2faaxcXFqV27dnJyctJf/vIXff/993bbKmyOjMlk0qRJk/Txxx+rbdu2MpvNatOmjT777LMSXyMAGBVBBjaXLl2Sm5ubLBaLGjRooCeffFIZGRmF9p08ebIOHz6syMhIDRw4UEuWLNELL7ygAQMGKDc3V1FRUbrrrrs0b948vf/++6Xa/rBhw5Senq7o6GgNGzZMsbGxioyMLHZMaGioLl68qE8//bTAa1m/fr1CQkJUu3ZtnT59Wr1799axY8c0Y8YMvfHGGxo5cqR27txZ7PrT0tK0e/duBQYGatasWbJYLHJ1ddWtt96qNWvW2PX9/vvvddNNN6lVq1Z27UFBQbblf/brr7/q4Ycf1oABAxQdHa0LFy5owIABWrFihaZMmaJRo0YpMjJSv/32m4YNG6a8vLxia5Wkbdu2aeLEiRo+fLheffVVZWZmasiQITp37lyJYwHAiNg3DUlXD0NNnz5dnTt3Vl5enj777DMtWrRI+/btU3x8fIHDGE2aNNHGjRtlMpk0ceJE/frrr5o3b54ee+wxLV68WJI0YcIE+fn5aenSpRo9enSJNXTq1Envvvuu7fm5c+f07rvv6pVXXilyzF133aWmTZtq9erVGjp0qK39008/1cWLFxUaGipJ2r59uy5cuKAtW7YoICDA1m/OnDnF1vTbb7/JarVq1apVqlOnjl599VVZLBa9/vrrGj58uNzc3BQcHCxJSk5OVpMmTQrsKfH29pYkJSUl2bX/8ssv2r59u7p2vToHqnXr1urTp48effRRHTx4UM2bN5ckeXh46LHHHtN///tf9ezZs9h6Dxw4oP379+u2226TJPXq1UsdOnTQf/7zH02aNKnYsQBgROyRgSQpOjpac+fO1bBhwzR8+HDFxsbq5Zdf1rfffqu1a9cW6D9+/Hi7L+wuXbrIarVq/PjxtrbatWsrICBAR44cKVUNjz/+uN3z7t2769y5c8Ue6jKZTBo6dKg2btxot/do9erVatq0qe666y5Jkru7uyRpw4YNys7OLlU9kmzrPHfunD755BM98cQTevjhh/XFF1+oYcOGdkHo8uXLMpvNBdaRPyfo8uXLdu2tW7e2hRjp6nsoSffcc48txPy5vTTv43333WcLMZLUvn17ubm5lfozAACjKXOQKe0pvYWdypv/uP/++0vcjp+fX6Fjr/2yg+NMmTJFtWrV0tatWwss+/MXrfS/s5t8fX0LtF+4cKFU27t2nR4eHpJU4vjQ0FBdvnxZ69atk3T1Z3Tjxo0aOnSoLWz16NFDQ4YMUWRkpBo1aqRBgwbpvffeU1ZWVrHrdnZ2liTdcssttkAhSa6urhowYIB2796tnJwcW9/C1peZmWm3rqJeb3HvoVTy+1DYOqWr72NpPwMAMJoyH1oq7Sm9hc2LSEhI0Ouvv67evXuXalsdO3bU1KlT7druuOOOspaMcsq/Xsr58+cLLCvq7JvC2q+d7FuUotZZ0vg777xTfn5+WrNmjR5++GGtX79ely9fth1Wkq4G67Vr12rnzp1av369Nm/erHHjxmn+/PnauXOnXF1dC123j4+PpKuH0q7VuHFjZWdn6+LFi7JYLPL29tZXX30lq9Vqt7cqOTnZbl0lvd7yvg/XOxYAjKjMQaa0p/QWdhpvfHy8TCaTRowYUaptNW3atFJOB0bh0tPTdfbsWXl6elZ1KSUaNmyYXn/9daWlpWn16tXy8/PTnXfeWaDfnXfeqTvvvFMvv/yyVq5cqZEjR2rVqlV65JFHCl2vj4+PvLy8lJiYWGBZUlKSnJycVL9+fUlXg/c777yjAwcOqHXr1rZ+u3btsi0HAFSsMh9aKs8pvZKUlZWlDz/8UD169FCzZs1KPe7KlStFnu6KipGZman09PQC7S+99JKsVqttMuuNLDQ0VFlZWVq2bJk+++wzDRs2zG75hQsXCuyVyA8WJR1eCg0N1fHjx/X555/b2s6ePatPPvlE99xzj2rVuvprNGjQINWtW1eLFi2y9bNarXrzzTfVtGlTdevW7XpeIgCgEJV21tLGjRuVkpKikSNHlnrMl19+KRcXF+Xm5urmm2/WlClT9PTTTxc7Jisry+6LqbiJojXBwoULlZKSYjtjZv369Tpx4oSkq6dQWywWnTx5Up06ddKIESNstyTYvHmzNm7cqODgYA0aNKjK6i+tzp07y9/fX//4xz+UlZVld1hJkpYtW6ZFixbpwQcf1G233ab09HS9/fbbcnNz0wMPPFDsumfOnKk1a9ZoyJAhevbZZ2WxWPTmm28qOztbUVFRtn7NmjXTM888o3nz5ik7O1uBgYH6+OOP9c0332jFihUVdjE8AMD/VFqQWbFihcxms0JCQkrVv3379rrrrrvUokULnTt3TrGxsXrmmWeUlJRU7Om40dHRJV57pCzKe3uAG0VMTIx+//132/O4uDjFxcVJunr4z2KxyN3dXf3799fnn3+uZcuWKTc3V/7+/oqKitK0adNsexxudKGhoXr55Zfl7++vzp072y3r0aOHdu/erVWrVunUqVOyWCwKCgrSihUrdMsttxS73iZNmmjbtm2aNm2aXnvtNWVnZ6tr165avny5OnToYNd37ty58vDw0FtvvaXY2FjdfvvtWr58uR5++OEKf70AAMlkvY5ZgPlzZN577z2FhYUV2S8tLU1NmjRR3759bV+iZWW1WtW3b1998cUXOnr0aJGHpwrbI+Pr66vU1FS5ubkV6J+ZmamjR4/abvIH1ET8HgD2boT77BmFo/7gT0tLk8ViKfL7O1+l/Kn94YcfKjMzs0yHla5lMpk0ZcoU5eTkFHvzQ7PZLDc3N7sHAAConiolyKxYsUIWi0X9+/e/rvXkX1+jsNOBAQBAzePwIJOcnKyvvvpKQ4YMKfSqp2WRf3VSI5wODAAAHM/hQWbVqlXKy8sr8rBSdna2Dh48aLtomHR1j0v+HYv/3G/u3LmqV6+eevXq5dCaAQCAMZTrrKXSnNKbb8WKFfLx8SnyZneJiYlq1aqVxowZY7vVwbp16zRnzhyFhITolltu0fnz57Vy5Ur9/PPPioqKKtd1bAAAQPVTriBTmlN6pat39/3uu+/07LPPlukU3nbt2ql169Zavny5zpw5o3r16qljx45as2aN3R2OAQBAzVauIHPs2LFS9WvRokWJ93jx8/Mr0Ocvf/mL7QaAlYV70aAm4+cfgFEZ40pnDlS3bl1J0qVLl6q4EqDq5P/85/8+AIBRVNqVfW9UtWvXlru7u06fPi1JcnFxsbtzMVCdWa1WXbp0SadPn5a7uzu3UQBgODU+yEiyTR7ODzNATePu7s4kegCGRJDR1asGe3t7q3HjxsrOzq7qcoBKVbduXfbEADAsgsyf1K5dm//QAQAwkBo/2RcAABgXQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABgWQQYAABhWmYNMRkaGwsPDFRwcrAYNGshkMik2NrZAv7CwMJlMpgKPli1blnpb69atU+fOneXk5KTmzZsrPDxcOTk5ZS0ZAABUU3XKOuDs2bOaPXu2mjdvrg4dOig+Pr7IvmazWe+8845dm8ViKdV2Nm3apMGDB6tnz55644039NNPP2nOnDk6ffq0Fi9eXNayAQBANVTmIOPt7a3k5GR5eXkpISFBgYGBRa+8Th2NGjWqXIVNmzZN7du315YtW1SnztUy3dzcFBUVpaeffrpMe3YAAED1VOZDS2azWV5eXqXun5ubq7S0tDJtY//+/dq/f78mTJhgCzGSNHHiRFmtVq1du7ZM6wMAANWTQyf7Xrp0SW5ubrJYLGrQoIGefPJJZWRklDju+++/lyQFBATYtfv4+KhZs2a25QAAoGYr86Gl0vL29tb06dPVuXNn5eXl6bPPPtOiRYu0b98+xcfH2+1puVZycrJtHYWtNykpqcixWVlZysrKsj0v694gAABgHA4LMtHR0XbPhw8frjvuuEP/+Mc/tHbtWg0fPrzIsZcvX5Z09TDWtZycnIoNJ9HR0YqMjCxn1QAAwEgq9ToyU6ZMUa1atbR169Zi+zk7O0uS3Z6VfJmZmbblhZk5c6ZSU1Ntj+PHj19f0QAA4IZVqUHG2dlZDRs21Pnz54vtl39IKf8Q058lJyfLx8enyLFms1lubm52DwAAUD1VapBJT0/X2bNn5enpWWy/jh07SpISEhLs2pOSknTixAnbcgAAULM5JMhkZmYqPT29QPtLL70kq9Wq4OBgW1t2drYOHjxot/elTZs2atmypZYsWaLc3Fxb++LFi2UymRQSEuKIsgEAgMGUa7LvwoULlZKSYjt7aP369Tpx4oQkafLkybpw4YI6deqkESNG2C5ct3nzZm3cuFHBwcEaNGiQbV2JiYlq1aqVxowZY3erg3nz5mngwIHq3bu3hg8frp9//lkLFy7UI488olatWpX39QIAgGqkXEEmJiZGv//+u+15XFyc4uLiJEmjRo2Su7u7+vfvr88//1zLli1Tbm6u/P39FRUVpWnTpqlWrZJ3BPXv319xcXGKjIzU5MmT5enpqVmzZunFF18sT8kAAKAaMlmtVmtVF+FIaWlpslgsSk1NZeIvAKBU5i/aUdUlGMbUiV0dst7Sfn9X6mRfAACAikSQAQAAhkWQAQAAhkWQAQAAhkWQAQAAhkWQAQAAhkWQAQAAhkWQAQAAhlWuK/sCAFCd3RHYtKpLQCkRZACgBFzltfQcdZVXoCgcWgIAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZV5iCTkZGh8PBwBQcHq0GDBjKZTIqNjbXrk5eXp9jYWA0cOFC+vr666aab1LZtW82ZM0eZmZml2k7Pnj1lMpkKPIKDg8taMgAAqKbqlHXA2bNnNXv2bDVv3lwdOnRQfHx8gT6XLl3S2LFjdeedd+rxxx9X48aNtWPHDoWHh+uLL77Ql19+KZPJVOK2mjVrpujoaLs2Hx+fspYMAACqqTIHGW9vbyUnJ8vLy0sJCQkKDAws0KdevXr69ttv1a1bN1vbo48+Kj8/P1uYue+++0rclsVi0ahRo8paIgAAqCHKfGjJbDbLy8ur2D716tWzCzH5HnzwQUnSgQMHSr29nJwcZWRklK1IAABQI1TqZN+TJ09Kkho1alSq/ocOHdJNN92k+vXry8vLSy+88IKys7MdWSIAADCQMh9auh6vvvqq3Nzc1Ldv3xL73nbbberVq5fatWunixcvau3atZozZ44OHTqk1atXFzkuKytLWVlZtudpaWkVUjsAALjxVFqQiYqK0tatW7Vo0SK5u7uX2P/dd9+1e/63v/1NEyZM0Ntvv60pU6bozjvvLHRcdHS0IiMjK6JkAABwg6uUQ0urV6/W888/r/Hjx+uJJ54o93qmTp0qSdq6dWuRfWbOnKnU1FTb4/jx4+XeHgAAuLE5fI/M559/rtGjR6tfv3568803r2tdvr6+kqTz588X2cdsNstsNl/XdgAAgDE4dI/Mrl279OCDDyogIEBr1qxRnTrXl5uOHDkiSfL09KyI8gAAgME5LMgcOHBA/fr1k5+fnzZs2CBnZ+ci+x48eFB//PGH7XlaWprdhF1JslqtmjNnjiSpT58+jikaAAAYSrl2kSxcuFApKSlKSkqSJK1fv14nTpyQJE2ePFm1atVSnz59dOHCBT333HP69NNP7cbfdttt6tq1q+15q1at1KNHD9tVgvfu3asRI0ZoxIgR8vf31+XLl/XRRx/p22+/1YQJE9S5c+fylA0AAKqZcgWZmJgY/f7777bncXFxiouLkyTblXjzJ9nOmDGjwPgxY8bYBZlr3Xzzzerevbs++ugjnTx5UrVq1VKrVq305ptvasKECeUpGQAAVEPlCjLHjh0rsY/Vai31+q7te8stt2jNmjVlLQsAANQwlXplXwAAgIpEkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZFkAEAAIZV5iCTkZGh8PBwBQcHq0GDBjKZTIqNjS2074EDBxQcHCxXV1c1aNBAf/vb33TmzJlSb2vdunXq3LmznJyc1Lx5c4WHhysnJ6esJQMAgGqqzEHm7Nmzmj17tg4cOKAOHToU2e/EiRO6++679euvvyoqKkrTpk3Tp59+qvvvv19XrlwpcTubNm3S4MGD5e7urjfeeEODBw/WnDlzNHny5LKWDAAAqqk6ZR3g7e2t5ORkeXl5KSEhQYGBgYX2i4qK0sWLF/Xdd9+pefPmkqSgoCDdf//9io2N1YQJE4rdzrRp09S+fXtt2bJFdepcLdPNzU1RUVF6+umn1bJly7KWDgAAqpky75Exm83y8vIqsd+HH36o/v3720KMJN1333264447tGbNmmLH7t+/X/v379eECRNsIUaSJk6cKKvVqrVr15a1bAAAUA05ZLJvYmKiTp8+rYCAgALLgoKC9P333xc7Pn/5teN9fHzUrFmzEscDAICaocyHlkojOTlZ0tXDUNfy9vbW+fPnlZWVJbPZXK7xSUlJRW47KytLWVlZtudpaWllqh0AABiHQ/bIXL58WZIKDSpOTk52fcozvrix0dHRslgstoevr2+ZagcAAMbhkCDj7OwsSXZ7RvJlZmba9SnP+OLGzpw5U6mpqbbH8ePHy1Q7AAAwDocEmfxDQvmHiP4sOTlZDRo0KPKwUmnG+/j4FDnWbDbLzc3N7gEAAKonhwSZpk2bytPTUwkJCQWW7d69Wx07dix2fP7ya8cnJSXpxIkTJY4HAAA1g8NuUTBkyBBt2LDB7tDOF198oUOHDmno0KG2tuzsbB08eNBu70ubNm3UsmVLLVmyRLm5ubb2xYsXy2QyKSQkxFFlAwAAAynXWUsLFy5USkqK7eyh9evX68SJE5KkyZMny2KxaNasWfrggw/Uq1cvPf3008rIyNC8efPUrl07jR071rauxMREtWrVSmPGjLG71cG8efM0cOBA9e7dW8OHD9fPP/+shQsX6pFHHlGrVq2u4yUDAIDqolxBJiYmRr///rvteVxcnOLi4iRJo0aNsp0t9PXXX+vZZ5/VjBkzVK9ePfXr10/z588vdn5Mvv79+ysuLk6RkZGaPHmyPD09NWvWLL344ovlKRkAAFRD5Qoyx44dK1W/Nm3aaPPmzcX28fPzk9VqLXTZ4MGDNXjw4DJWBwAAagqHzZEBAABwNIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwLIIMAAAwrDpVXQBgNPMX7ajqEgxj6sSuVV0CgGqOPTIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwCDIAAMCwuCAeAJTgjsCmVV0CgCKwRwYAABiWw4JMWFiYTCZTkY/ExMQix0ZERBQ6xsnJyVHlAgAAA3LYoaXHHntM9913n12b1WrV448/Lj8/PzVtWvKu2sWLF8vV1dX2vHbt2hVeJwAAMC6HBZmuXbuqa1f7G8Zt27ZNly5d0siRI0u1jpCQEDVq1MgR5QEAgGqgUufIrFy5UiaTSQ8//HCp+lutVqWlpclqtTq4MgAAYESVFmSys7O1Zs0adevWTX5+fqUac+utt8pisah+/foaNWqUTp065dgiAQCAoVTa6debN2/WuXPnSnVYycPDQ5MmTVLXrl1lNpv1zTff6F//+pd2796thIQEubm5FTk2KytLWVlZtudpaWkVUj8AALjxVFqQWblyperWrathw4aV2Pfpp5+2ez5kyBAFBQVp5MiRWrRokWbMmFHk2OjoaEVGRl53vQAA4MZXKYeWMjIy9Mknn6hPnz5q2LBhudbx8MMPy8vLS1u3bi2238yZM5Wammp7HD9+vFzbAwAAN75K2SPz8ccfl+lspaL4+vrq/PnzxfYxm80ym83XtR0AAGAMlbJHZsWKFXJ1ddXAgQPLvQ6r1apjx47J09OzAisDAABG5vAgc+bMGW3dulUPPvigXFxcCiz/448/dPDgwQJjrrV48WKdOXNGwcHBDqsVAAAYi8MPLa1evVo5OTlFHlYaPXq0vv76a7trxdx8880KDQ1Vu3bt5OTkpG3btmnVqlXq2LGjHnvsMUeXDAAADMLhQWbFihVq3LhxgdsVFGfkyJHavn27PvzwQ2VmZurmm2/W9OnT9Y9//KPQvToAAKBmcniQ2bFjR7HL4+PjC7S9/fbbDqoGAABUJ5V6iwIAAICKRJABAACGRZABAACGRZABAACGRZABAACGRZABAACGRZABAACGRZABAACGRZABAACGRZABAACG5fBbFAAAYDR/ud2zqktAKbFHBgAAGBZBBgAAGBZBBgAAGBZBBgAAGBZBBgAAGBZnLQFldEdg06ouAQDw/2OPDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyCDAAAMCyHBZn4+HiZTKZCHzt37ixxfGJiooYNGyZ3d3e5ublp0KBBOnLkiKPKBQAABuTwey099dRTCgwMtGvz9/cvdkxGRoZ69eql1NRUzZo1S3Xr1tVrr72mHj166IcfflDDhg0dWTIAADAIhweZ7t27KyQkpExjFi1apMOHD2v37t22ENS3b1+1bdtW8+fPV1RUlCNKBQAABlMpc2TS09OVk5NT6v5r165VYGCg3Z6cli1b6t5779WaNWscUSIAADAghweZsWPHys3NTU5OTurVq5cSEhKK7Z+Xl6cff/xRAQEBBZYFBQXpt99+U3p6uqPKBQAABuKwQ0v16tXTkCFD9MADD6hRo0bav3+/YmJi1L17d23fvl2dOnUqdNz58+eVlZUlb2/vAsvy25KSktSiRYtCx2dlZSkrK8v2PC0trQJeDQAAuBE5LMh069ZN3bp1sz0fOHCgQkJC1L59e82cOVOfffZZoeMuX74sSTKbzQWWOTk52fUpTHR0tCIjI6+ndAAAYBCVeh0Zf39/DRo0SF999ZVyc3ML7ePs7CxJdntV8mVmZtr1KczMmTOVmppqexw/frwCKgcAADcih5+1dC1fX19duXJFFy9elJubW4HlDRo0kNlsVnJycoFl+W0+Pj5Frt9sNhe6NwcAAFQ/lX5l3yNHjsjJyUmurq6FLq9Vq5batWtX6KTgXbt26dZbb1X9+vUdXSYAADAAhwWZM2fOFGjbt2+f1q1bp969e6tWraub/uOPP3Tw4EG7fiEhIdqzZ49dmPnll1/05ZdfaujQoY4qGQAAGIzDDi2FhobK2dlZ3bp1U+PGjbV//34tWbJELi4umjt3rq3f6NGj9fXXX8tqtdraJk6cqLffflv9+vXTtGnTVLduXS1YsEBNmjTR1KlTHVUyAAAwGIcFmcGDB2vFihVasGCB0tLS5OnpqYceekjh4eEl3qKgfv36io+P15QpUzRnzhzl5eWpZ8+eeu211+Tp6emokgEAgMGYrH/eFVINpaWlyWKxKDU1tdDJxUBZrd/zR1WXYBgDAptXdQkVgs+89KrLZ56UUvRlPmDPx73oM4mvR2m/vyt9si8AAEBFIcgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDIsgAAADDcliQ2bNnjyZNmqQ2bdropptuUvPmzTVs2DAdOnSoxLGxsbEymUyFPk6ePOmokgEAgMHUcdSKX3nlFX377bcaOnSo2rdvr5MnT2rhwoXq3Lmzdu7cqbZt25a4jtmzZ+uWW26xa3N3d3dQxQAAwGgcFmSeffZZrVy5UvXq1bO1hYaGql27dpo7d66WL19e4jr69u2rgIAAR5UIAAAMzmGHlrp162YXYiTp9ttvV5s2bXTgwIFSryc9PV25ubkVXR4AAKgGKnWyr9Vq1alTp9SoUaNS9e/Vq5fc3Nzk4uKigQMH6vDhww6uEAAAGInDDi0VZsWKFUpMTNTs2bOL7efi4qKwsDBbkPnuu++0YMECdevWTXv37pWvr2+RY7OyspSVlWV7npaWVmH1AwCAG4vJarVaK2NDBw8eVJcuXdSmTRt98803ql27dpnGb9u2TXfffbcmTJigN998s8h+ERERioyMLNCempoqNze3MtcNXGv9nj+qugTDGBDYvKpLqBB85qVXXT7zpJTLVV2CYfi4OztkvWlpabJYLCV+f1fKoaWTJ0+qX79+slgsWrt2bZlDjCTddddd6tKli7Zu3Vpsv5kzZyo1NdX2OH78eHnLBgAANziHH1pKTU1V3759lZKSom+++UY+Pj7lXpevr69++eWXYvuYzWaZzeZybwMAABiHQ4NMZmamBgwYoEOHDmnr1q1q3br1da3vyJEj8vT0rKDqAACA0Tns0FJubq5CQ0O1Y8cOffDBB+ratWuh/ZKTk3Xw4EFlZ2fb2s6cOVOg38aNG/Xdd98pODjYUSUDAACDcdgemalTp2rdunUaMGCAzp8/X+ACeKNGjZJ0dU7LsmXLdPToUfn5+Um6eg2aTp06KSAgQBaLRXv37tXSpUvl6+urWbNmOapkAABgMA4LMj/88IMkaf369Vq/fn2B5flBpjChoaH69NNPtWXLFl26dEne3t569NFHFR4eriZNmjiqZAAAYDCVdvp1VSnt6VtAaXFaZuk56rTMysbp16XH6dc1T1Wffl2pF8QDACP6y+2cZADcqCr1FgUAAAAViSADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMiyADAAAMq05VF2Bk8xftqOoSDGPqxK5VXQIAoBpijwwAADAsggwAADAshx5aysrK0osvvqj3339fFy5cUPv27TVnzhzdf//9JY5NTEzUlClTtGXLFuXl5alXr1567bXXdOuttzqy5DK5I7BpVZcAAECN5tA9MmFhYVqwYIFGjhyp119/XbVr19YDDzygbdu2FTsuIyNDvXr10tdff61Zs2YpMjJS33//vXr06KFz5845smQAAGAgDtsjs3v3bq1atUrz5s3TtGnTJEmjR49W27ZtNX36dG3fvr3IsYsWLdLhw4e1e/duBQYGSpL69u2rtm3bav78+YqKinJU2QAAwEActkdm7dq1ql27tiZMmGBrc3Jy0vjx47Vjxw4dP3682LGBgYG2ECNJLVu21L333qs1a9Y4qmQAAGAwDtsj8/333+uOO+6Qm5ubXXtQUJAk6YcffpCvr2+BcXl5efrxxx81bty4AsuCgoK0ZcsWpaenq379+oVuNysrS1lZWbbnqampkqS0tLRyv5aiXMpIr/B1VleOeP+rSnra5aouwTDSamVXdQkVgs+89PjMax5Hfeb53xtWq7XYfg4LMsnJyfL29i7Qnt+WlJRU6Ljz588rKyurxLEtWrQodHx0dLQiIyMLtBcWmgAAwI0tPT1dFoulyOUOCzKXL1+W2Wwu0O7k5GRbXtQ4SeUaK0kzZ87Us88+a3uel5en8+fPq2HDhjKZTKV/AQaVlpYmX19fHT9+vMDeMFRPfOY1D595zVTTPner1ar09HT5+PgU289hQcbZ2dnuEE++zMxM2/Kixkkq11jpagC6NgS5u7uXqubqxM3NrUb8oON/+MxrHj7zmqkmfe7F7YnJ57DJvt7e3kpOTi7Qnt9WVMJq0KCBzGZzucYCAICaxWFBpmPHjjp06FCBSZ67du2yLS+0oFq11K5dOyUkJBRYtmvXLt16661FTvQFAAA1i8OCTEhIiHJzc7VkyRJbW1ZWlt577z116dLFNvn2jz/+0MGDBwuM3bNnj12Y+eWXX/Tll19q6NChjiq5WjCbzQoPDy90jhGqJz7zmofPvGbicy+cyVrSeU3XYdiwYfroo480ZcoU+fv7a9myZdq9e7e++OIL3X333ZKknj176uuvv7Y7vSo9PV2dOnVSenq6pk2bprp162rBggXKzc3VDz/8IE9PT0eVDAAADMSh91r697//rRdeeMHuXksbNmywhZii1K9fX/Hx8ZoyZYrmzJmjvLw89ezZU6+99hohBgAA2Dh0jwwAAIAjOfSmkQAAAI5EkLmBmUwmu8exY8cK7RcWFmbXLyIiwm55RESE3fKwsDCH1w4AQGUgyABV6NixY7aA6eXlpZycnEL7HThwwNbPz8/P1h4bGyuTyaS5c+eWuK1rA63JZNJNN92k9u3bKyIiQhcvXqyolwX977MNDg4use+5c+c0Y8YMtWnTRi4uLnJxcdHNN9+se++9V5GRkTp16pSkqydHXPsZFveIj4+XJPn5+dnafv7550JryM3NVdOmTUv8wwkV78//D/Tp06fQPjt37izwh2j+H7E7d+6spEpvTA6d7AugdOrUqaNTp05p48aNGjhwYIHl7777rmrVqpi/O4YMGaK2bdtKunqRyXXr1ikyMlLr16/Xjh07VK9evQrZDkrnxIkT6tatm44fP66OHTtq7Nixcnd3V3JysrZv366IiAj99a9/VZMmTRQWFqaePXvajf/444+1b98+jRkzxi7kSrJ7nv/zs3TpUi1YsKBAHZs2bVJSUpLq1KlTZKCG423ZskVffvml7rnnnqouxTAIMsANoFu3btq3b5+WLl1aIMjk5ORo+fLluu+++/T1119f97ZCQkI0fPhw2/OYmBgFBQVp7969WrlyJYceK1l4eLiOHz+u2bNn64UXXiiw/KeffrLdZqWwz+bYsWPat29foSHnz+rWrau7775by5cv1yuvvKK6devaLV+6dKksFos6dOig//73v9fzklBOfn5++uOPP/T3v/9du3fvrhH3B6wIHFoCbgDOzs4aPny4Pv30U50+fdpu2YYNG3Tq1CmNGzfOIduuX7++7Qtyz549DtkGirZjxw5J0uTJkwtd3q5dO9sFRK/XuHHjdObMGa1fv96u/cyZM9qwYYNGjBhR7L3s4FgtWrTQ3/72NyUkJGjNmjVVXY5hEGSAG8S4ceOUk5Oj999/36596dKlatCggQYPHuzwGvgLsPI1bNhQknTo0CGHb+vBBx+Uh4eH3nvvPbv2999/X9nZ2Q4Lyyi92bNny2w26/nnn1d2dnZVl2MIBBkDmThxokJCQgo88if0wdiCgoLUtm1buy+ZkydPatOmTRo5cqTDLkuekZGhf//737YaULmGDRsmSRowYIDCw8MVHx9f4B51FcVsNmvkyJH67LPPdPLkSVv70qVL1a5dOwUGBjpkuyi95s2ba/Lkyfr111/11ltvVXU5hsAcGQPZtGlTVZcABxs3bpyeffZZ7dq1S126dNGyZcuUk5NToX8pr1271nZ/s1OnTmndunVKSkpSQECA3dwZVI5Jkybp+PHjev311zV79mzNnj1bJpNJrVq10oABA/T000/L29u7wrY3btw4LVy4UMuWLdPf//537dq1S//v//0/vfbaaxW2DVyfWbNm6Z133tFLL72ksLAwubq6VnVJNzT2yAA3kFGjRqlu3bpaunSpJOm9995Tp06dirxbfHl8+OGHioyMVGRkpP7973+rYcOGioiIUHx8PGcsVQGTyaRXX31ViYmJWrZsmZ544gkFBATo4MGDeuWVV9S6dWvt2rWrwraX//OUv+dv6dKlqlevnkaNGlVh28D18fDw0IwZM3T69GnFxMRUdTk3PIKMgRw9elRWq7XAY8yYMVVdGiqIp6enBgwYoFWrVmnr1q365ZdfKnzewn/+8x/bz87Fixf1448/Kjw8XDfddFOFbgdl06hRI40ePVqLFi3S7t27lZiYqCFDhiglJUUTJkyo0G2NGzdOv/zyi7Zu3apVq1ZpwIABatSoUYVuA9fnqaeeUrNmzTR//vwCJwDAHkEGuMGMHz9eaWlpCgsLk5OTk0aOHFnVJaEKeHl56f3335fZbNaPP/6oc+fOVdi68+dchYWFKS0tTePHj6+wdaNiODs7KzIyUhkZGYqMjKzqcm5oBBngBtOnTx81bdpUiYmJGjx4sDw8PKq6JFQRs9lc4HovFSH/LLjExEQ1bdq0yKvJomqNGTNGbdq00dtvv61ff/21qsu5YTHZF7jB1K5dWx9//LFOnDhRoXNjcGOaP3+++vXrp5YtWxZYtnDhQmVkZKhly5a207Qryty5czV8+HA1a9aswq4ajYpVu3ZtRUVFadCgQQXuoYf/IcjUQPHx8QoJCSly+dq1ayuxGhQmICBAAQEBpe7/wQcf2M5EutbgwYMr5Ro0KNxPP/1U5NWSW7ZsqVWrVmnatGlq166dunTposaNGyslJUU7d+7U3r175ezsrMWLF1d4XX5+fgVuaYAbz8CBA3XXXXdp27ZtRfZ56aWX5OnpWeiyGTNmFBqSqxOCTA30+++/6/fff6/qMlCB9u7dq7179xa6zM/PjyBThZKSkrRs2bJCl/Xo0UPvvfee1q9fry+//FKbN2/WqVOnVLt2bd1888164oknNGXKFN1+++2VXDVuJK+88or++te/Frl848aNRS4LCwur9kHGZLVarVVdBAp37VVWjx49WuhfUGFhYXb/UYaHh9vthoyIiCjTZDF+JAAARkGQAQAAhsUMLwAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFgEGQAAYFj/H31zlzJKuzpJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_mce = all_model_mce.sort_values(by = \"15min vs 60min\", axis=1)\n",
    "all_model_mce = all_model_mce.rename(columns={\"Neural Laplace\":\"NL\"})\n",
    "# all_model_mce.to_csv(\"wind_mce.csv\")\n",
    "colors = plt.cm.BuPu(np.linspace(0.1, 0.5, len(all_model_mce)))\n",
    "n_rows = len(all_model_mce)\n",
    "\n",
    "index = np.arange(len(all_model_mce.columns))\n",
    "bar_width = 0.6\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(all_model_mce.columns))\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    ax.bar(all_model_mce.columns, all_model_mce.iloc[row, :], bar_width, bottom=y_offset, color=colors[row], label=all_model_mce.index[row])\n",
    "    y_offset = y_offset + all_model_mce.iloc[row, :]\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "for i, tick in enumerate(ax.get_xticklabels()):\n",
    "    tick.set_fontsize(14)\n",
    "\n",
    "    if i == 0:\n",
    "        tick.set_fontweight('bold')\n",
    "        tick.set_fontsize(16)\n",
    "\n",
    "for i, tick in enumerate(ax.get_yticklabels()):\n",
    "    tick.set_fontsize(12)\n",
    "ax.ticklabel_format(style='sci', scilimits=(-1,2), axis='y')\n",
    "# fig.savefig(\"savings/mce_wind.pdf\",bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
